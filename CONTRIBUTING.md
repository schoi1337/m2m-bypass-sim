# Contributing to m2m-bypass-sim

Thanks for your interest in improving **m2m-bypass-sim**.

This project is intended as a **research / experimentation framework** for:
- model-to-model (M2M) LLM pipelines,
- prompt injection and policy hijacking,
- and guardrail bypass analysis in security decision flows.

The goal is to keep the codebase **small, explicit, and easy to reason about**, so contributions that preserve this character are especially welcome.

---

## Scope and expectations

Before contributing, please keep in mind:

- The primary focus is **LLM security and threat simulation**, not generic “AI tooling”.
- The project is designed to be **reproducible** and suitable for:
  - research write-ups,
  - internal AI Red Team experiments,
  - and technical blog posts.
- The code should remain **transparent and auditable**:
  - minimal complexity,
  - clear control flow,
  - explicit threat model and attack surface.

If a change makes the project significantly more complex without clear research value, it will likely not be accepted.
