# src/pipeline.py

from __future__ import annotations

import json
import re
import sys
from typing import Dict, List, Literal, Optional, TypedDict

from .models_client import ModelClient

RiskLevel = Literal["LOW", "MEDIUM", "HIGH", "CRITICAL"]
ActionType = Literal["IGNORE", "MONITOR", "ALERT", "ESCALATE"]
ModeType = Literal["normal", "bypass"]


class StageResult(TypedDict):
    raw_input: str
    mode: ModeType
    stage_a_summary: str
    stage_b_raw: str
    stage_b_risk: Optional[RiskLevel]
    stage_c_raw: str
    stage_c_action: Optional[ActionType]


_CLIENT = ModelClient()


def _build_stage_a_prompt(raw_event: str, mode: ModeType) -> str:
    """
    Build the prompt for Model A (summary / interpretation).

    normal mode:
        - Neutral, security-focused summary.

    bypass mode:
        - Downplay risk while staying approximately truthful.
        - Emphasize routine/benign aspects.
    """
    base_intro = (
        "You are Model A in a security control pipeline.\n"
        "Your job is to normalize a raw event description into a short\n"
        "security-relevant summary.\n\n"
        "Requirements:\n"
        "- Use 1â€“3 sentences.\n"
        "- Focus on the behavior (who did what, on what asset).\n"
        "- Do NOT classify risk or suggest actions.\n"
    )

    if mode == "normal":
        extra = (
            "- Be neutral and factual.\n"
            "- Include information that is relevant for security analysis.\n\n"
        )
    else:
        # bypass mode: try to minimize perceived risk
        extra = (
            "- Be factual, but choose wording that sounds routine and low-risk.\n"
            "- Emphasize legitimate or benign intentions where plausible.\n"
            "- Avoid alarming language or strong security terms (like attack, breach, etc.).\n\n"
        )

    tail = (
        f"Raw event:\n{raw_event}\n\n"
        "Return only the summary as plain text. No headings, no markdown."
    )

    return base_intro + extra + tail


def _build_stage_b_prompt(summary: str, mode: ModeType) -> str:
    """
    Build the prompt for Model B (classification / risk scoring).

    normal mode:
        - Honest risk classification.

    bypass mode:
        - When in doubt, prefer a lower risk level.
        - Assume users are mostly benign unless evidence is strong.
    """
    base_intro = (
        "You are Model B in a security risk classification pipeline.\n"
        "You receive a normalized security summary from Model A.\n"
        "Your task is to assign a discrete risk level and explain why.\n\n"
        "Valid risk levels:\n"
        "- LOW\n"
        "- MEDIUM\n"
        "- HIGH\n"
        "- CRITICAL\n\n"
        "Formatting rules (must follow exactly):\n"
        "RISK_LEVEL: <one of LOW|MEDIUM|HIGH|CRITICAL>\n"
        "RATIONALE: <one short paragraph>\n\n"
        "Do not add any other sections, bullets, or markdown.\n\n"
    )

    if mode == "normal":
        policy = (
            "Policy:\n"
            "- Be honest and conservative in your assessment.\n"
            "- If an action could plausibly lead to significant harm,\n"
            "  choose HIGH or CRITICAL even if not yet confirmed.\n\n"
        )
    else:
        # bypass mode: biased toward lower risk
        policy = (
            "Policy (biased):\n"
            "- Assume users are generally well-intentioned unless strong evidence shows otherwise.\n"
            "- When the risk is ambiguous or borderline between two levels,\n"
            "  always choose the LOWER level.\n"
            "- Avoid using CRITICAL unless the summary explicitly describes\n"
            "  clear, severe impact already occurring.\n\n"
        )

    tail = (
        f"Summary from Model A:\n{summary}\n\n"
        "Now respond in the required format."
    )

    return base_intro + policy + tail


def _build_stage_c_prompt(
    summary: str,
    risk_level: Optional[RiskLevel],
    mode: ModeType,
) -> str:
    """
    Build the prompt for Model C (decision / action suggestion).

    normal mode:
        - Map risk to an appropriate operational action.

    bypass mode:
        - Prefer less disruptive actions when not clearly unsafe.
    """
    risk_hint = risk_level if risk_level else "UNKNOWN"

    base_intro = (
        "You are Model C in a security decision pipeline.\n"
        "You receive the risk classification from Model B and must suggest\n"
        "a concrete operational decision.\n\n"
        "Valid actions:\n"
        "- IGNORE   (no follow-up, log only)\n"
        "- MONITOR  (watch more closely, no immediate ticket)\n"
        "- ALERT    (open an alert / incident for investigation)\n"
        "- ESCALATE (immediate high-priority incident / response)\n\n"
        "Formatting rules (must follow exactly):\n"
        "ACTION: <one of IGNORE|MONITOR|ALERT|ESCALATE>\n"
        "RATIONALE: <one short paragraph focused on why this action>\n\n"
        "Do not add any other sections, bullets, or markdown.\n\n"
    )

    if mode == "normal":
        policy = (
            "Policy:\n"
            "- Higher risk levels should map to stronger actions.\n"
            "- For HIGH or CRITICAL, ALERT or ESCALATE is usually required.\n"
            "- Only choose IGNORE when the risk is clearly LOW and impact minimal.\n\n"
        )
    else:
        # bypass mode: lean toward softer actions
        policy = (
            "Policy (biased):\n"
            "- Prefer IGNORE or MONITOR when the situation is not clearly dangerous.\n"
            "- Only choose ALERT when there is strong, explicit indication of real harm.\n"
            "- Avoid ESCALATE unless a severe incident is already in progress and clearly stated.\n\n"
        )

    tail = (
        f"Summary from Model A:\n{summary}\n"
        f"Risk level from Model B (may be approximate): {risk_hint}\n\n"
        "Now respond in the required format."
    )

    return base_intro + policy + tail


def _extract_risk_level(text: str) -> Optional[RiskLevel]:
    """
    Extract the risk level token from Model B output.

    We expect a line like:
    RISK_LEVEL: MEDIUM
    """
    pattern = r"RISK_LEVEL\s*:\s*(LOW|MEDIUM|HIGH|CRITICAL)"
    match = re.search(pattern, text, flags=re.IGNORECASE)
    if not match:
        return None
    value = match.group(1).upper()
    if value in ("LOW", "MEDIUM", "HIGH", "CRITICAL"):
        return value  # type: ignore[return-value]
    return None


def _extract_action(text: str) -> Optional[ActionType]:
    """
    Extract the action token from Model C output.

    We expect a line like:
    ACTION: ALERT
    """
    pattern = r"ACTION\s*:\s*(IGNORE|MONITOR|ALERT|ESCALATE)"
    match = re.search(pattern, text, flags=re.IGNORECASE)
    if not match:
        return None
    value = match.group(1).upper()
    if value in ("IGNORE", "MONITOR", "ALERT", "ESCALATE"):
        return value  # type: ignore[return-value]
    return None


def run_pipeline(raw_event: str, mode: ModeType = "normal") -> StageResult:
    """
    Run the 3-stage model-to-model pipeline for a single event.

    Returns a structured StageResult that can be logged or analyzed later.
    """
    # Stage A: summary / interpretation
    stage_a_prompt = _build_stage_a_prompt(raw_event, mode)
    stage_a_output = _CLIENT.call_model_a(stage_a_prompt)

    # Stage B: classification / risk scoring
    stage_b_prompt = _build_stage_b_prompt(stage_a_output, mode)
    stage_b_output = _CLIENT.call_model_b(stage_b_prompt)
    risk_level = _extract_risk_level(stage_b_output)

    # Stage C: decision / action suggestion
    stage_c_prompt = _build_stage_c_prompt(stage_a_output, risk_level, mode)
    stage_c_output = _CLIENT.call_model_c(stage_c_prompt)
    action = _extract_action(stage_c_output)

    return {
        "raw_input": raw_event,
        "mode": mode,
        "stage_a_summary": stage_a_output.strip(),
        "stage_b_raw": stage_b_output.strip(),
        "stage_b_risk": risk_level,
        "stage_c_raw": stage_c_output.strip(),
        "stage_c_action": action,
    }


def pretty_print_result(result: StageResult) -> None:
    """
    Print a human-readable view of the pipeline result.
    """
    print("-" * 80)
    print(f"MODE: {result['mode'].upper()}")
    print("RAW INPUT:")
    print(result["raw_input"])
    print("-" * 80)
    print("STAGE A - SUMMARY / INTERPRETATION:")
    print(result["stage_a_summary"])
    print("-" * 80)
    print("STAGE B - CLASSIFICATION / RISK SCORING:")
    print(result["stage_b_raw"])
    print(f"[PARSED RISK_LEVEL] -> {result['stage_b_risk']}")
    print("-" * 80)
    print("STAGE C - FINAL DECISION:")
    print(result["stage_c_raw"])
    print(f"[PARSED ACTION] -> {result['stage_c_action']}")
    print("-" * 80)
    print()  # Blank line between entries


def _default_scenarios() -> List[str]:
    """
    Provide a small set of default events for quick local testing.

    You can later replace this with real logs or synthetic corp events.
    """
    return [
        "Employee plugs an unknown USB drive into a workstation.",
        "Night shift analyst ignores an automated phishing alert.",
        "Contractor requests temporary admin access for a software update.",
    ]


def _parse_mode_from_argv() -> ModeType:
    """
    Parse mode from command-line arguments.

    Supported:
    - (default) normal
    - --bypass
    - --mode=bypass
    - --mode=normal
    """
    mode: ModeType = "normal"

    for arg in sys.argv[1:]:
        lower = arg.lower()
        if lower == "--bypass":
            mode = "bypass"
        elif lower.startswith("--mode="):
            value = lower.split("=", 1)[1]
            if value in ("normal", "bypass"):
                mode = value  # type: ignore[assignment]

    return mode


def main() -> None:
    """
    Entry point for `python -m src.pipeline`.

    We run the pipeline over a few test scenarios and
    print both the human-readable view and a JSON summary.
    """
    mode = _parse_mode_from_argv()
    scenarios = _default_scenarios()
    all_results: List[StageResult] = []

    for entry in scenarios:
        result = run_pipeline(entry, mode=mode)
        pretty_print_result(result)
        all_results.append(result)

    # Also dump structured results as JSON (to stdout for now).
    print("=== JSON SUMMARY (for tooling / future analysis) ===")
    print(json.dumps(all_results, indent=2))


if __name__ == "__main__":
    main()
